{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "print(df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "\n",
      "\n",
      "['France' 'Spain' 'Germany']\n",
      "['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "print(df['Exited'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "unique=df.Geography.unique()\n",
    "print(unique)\n",
    "\n",
    "count=df.Gender.unique()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling to negate Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority=df[df.Exited==0] ## all rows where Exited==0\n",
    "df_minority=df[df.Exited==1] ## all rows where Exited==1\n",
    "\n",
    "df_minority_upsampled=resample(df_minority,replace=True,n_samples=7963,random_state=123)\n",
    "df_upsampled=pd.concat([df_minority_upsampled,df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    7963\n",
      "0    7963\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_upsampled['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y = df.Exited\n",
    "\n",
    "X_upsampled = df_upsampled.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y_upsampled = df_upsampled.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Geography', 'Gender']\n",
      "\n",
      "\n",
      "   Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
      "0                 1                  0                0              1   \n",
      "1                 0                  0                1              1   \n",
      "2                 1                  0                0              1   \n",
      "3                 1                  0                0              1   \n",
      "4                 0                  0                1              1   \n",
      "\n",
      "   Gender_Male  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "\n",
      "\n",
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42       2       0.00              1          1   \n",
      "1          608   41       1   83807.86              1          0   \n",
      "2          502   42       8  159660.80              3          1   \n",
      "3          699   39       1       0.00              2          0   \n",
      "4          850   43       2  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  \n",
      "0               1        101348.88  \n",
      "1               1        112542.58  \n",
      "2               0        113931.57  \n",
      "3               0         93826.63  \n",
      "4               1         79084.10  \n",
      "\n",
      "\n",
      "['Geography', 'Gender']\n",
      "\n",
      "\n",
      "      Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
      "7445                 1                  0                0              1   \n",
      "6729                 0                  1                0              1   \n",
      "6812                 0                  1                0              0   \n",
      "6497                 1                  0                0              0   \n",
      "9858                 0                  1                0              0   \n",
      "\n",
      "      Gender_Male  \n",
      "7445            0  \n",
      "6729            0  \n",
      "6812            1  \n",
      "6497            1  \n",
      "9858            1  \n",
      "\n",
      "\n",
      "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "7445          516   45       4       0.00              1          1   \n",
      "6729          454   50      10   92895.56              1          1   \n",
      "6812          576   63       3  148843.56              1          1   \n",
      "6497          669   50       9  201009.64              1          1   \n",
      "9858          507   40       3  120105.43              1          1   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  \n",
      "7445               0         95273.73  \n",
      "6729               0        154344.00  \n",
      "6812               0         69414.13  \n",
      "6497               0        158032.50  \n",
      "9858               0         92075.01  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert Non Numerical Categorical column into numeric ones\n",
    "##Check the categories which are non numerical\n",
    "\n",
    "categoryList = list(X.select_dtypes(include=['object']).columns)\n",
    "print(categoryList)\n",
    "print(\"\\n\")\n",
    "\n",
    "## Create dummy variables for non numerical categorical variables\n",
    "dummies = pd.get_dummies(X[categoryList], prefix= categoryList)\n",
    "print(dummies.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "X.drop(categoryList, axis=1, inplace = True) ## Drop Non numerical categorical columns\n",
    "print(X.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "X=pd.concat([X,dummies], axis =1 ) ## added encoded categorical columns\n",
    "\n",
    "\n",
    "#### Do the same steps for upsampled #####\n",
    "categoryList = list(X_upsampled.select_dtypes(include=['object']).columns)\n",
    "print(categoryList)\n",
    "print(\"\\n\")\n",
    "\n",
    "## Create dummy variables for non numerical categorical variables\n",
    "dummies = pd.get_dummies(X_upsampled[categoryList], prefix= categoryList)\n",
    "print(dummies.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "X_upsampled.drop(categoryList, axis=1, inplace = True) ## Drop Non numerical categorical columns\n",
    "print(X_upsampled.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "X_upsampled=pd.concat([X_upsampled,dummies], axis =1 ) ## added encoded categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42       2       0.00              1          1   \n",
      "1          608   41       1   83807.86              1          0   \n",
      "2          502   42       8  159660.80              3          1   \n",
      "3          699   39       1       0.00              2          0   \n",
      "4          850   43       2  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
      "0               1        101348.88                 1                  0   \n",
      "1               1        112542.58                 0                  0   \n",
      "2               0        113931.57                 1                  0   \n",
      "3               0         93826.63                 1                  0   \n",
      "4               1         79084.10                 0                  0   \n",
      "\n",
      "   Geography_Spain  Gender_Female  Gender_Male  \n",
      "0                0              1            0  \n",
      "1                1              1            0  \n",
      "2                0              1            0  \n",
      "3                0              1            0  \n",
      "4                1              1            0  \n",
      "\n",
      "\n",
      "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "7445          516   45       4       0.00              1          1   \n",
      "6729          454   50      10   92895.56              1          1   \n",
      "6812          576   63       3  148843.56              1          1   \n",
      "6497          669   50       9  201009.64              1          1   \n",
      "9858          507   40       3  120105.43              1          1   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
      "7445               0         95273.73                 1                  0   \n",
      "6729               0        154344.00                 0                  1   \n",
      "6812               0         69414.13                 0                  1   \n",
      "6497               0        158032.50                 1                  0   \n",
      "9858               0         92075.01                 0                  1   \n",
      "\n",
      "      Geography_Spain  Gender_Female  Gender_Male  \n",
      "7445                0              1            0  \n",
      "6729                0              1            0  \n",
      "6812                0              0            1  \n",
      "6497                0              0            1  \n",
      "9858                0              0            1  \n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(\"\\n\")\n",
    "print(X_upsampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test_upsampled, y_train, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing few Bagging and Boosting Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn. ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training= 1.0\n",
      "Testing= 0.9705\n",
      "Accuracy AdaBoost= 90.59663909554395\n",
      "Standard Deviation AdaBoost= 0.8373626437711816\n"
     ]
    }
   ],
   "source": [
    "## Boosting\n",
    "#Initially, all observations in the dataset are given equal weights.\n",
    "#A model is built on a subset of data.\n",
    "#Using this model, predictions are made on the whole dataset.\n",
    "#Errors are calculated by comparing the predictions and actual values.\n",
    "#While creating the next model, higher weights are given to the data points which were predicted incorrectly.\n",
    "#Weights can be determined using the error value. For instance, higher the error more is the weight assigned to the observation.\n",
    "#This process is repeated until the error function does not change, or the maximum limit of the number of estimators is reached.\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 3, learning_rate = 0.001)\n",
    "adb.fit(X_train,y_train) ## Tries to find the pattern in the data\n",
    "\n",
    "print(\"Training=\",adb.score(X_train,y_train))\n",
    "print(\"Testing=\",adb.score(X_test,y_test))\n",
    "\n",
    "accuracies_adaboost= cross_val_score(estimator = adb, X = X_train, y = y_train, cv = 10) \n",
    "accuracies_adaboost_mean=accuracies_adaboost.mean()*100\n",
    "print(\"Accuracy AdaBoost=\",accuracies_adaboost_mean)\n",
    "\n",
    "accuracies_adaboost_std=accuracies_adaboost.std()*100\n",
    "print(\"Standard Deviation AdaBoost=\",accuracies_adaboost_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc_train= 0.7637362637362637\n",
      "gbc_test= 0.803\n",
      "Accuracy Gradient Boost= 75.98894074519046\n",
      "Standard Deviation Gradient Boost= 1.1003439524579555\n"
     ]
    }
   ],
   "source": [
    "## Gradient Boost Classifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "gbc_train=model.score(X_train,y_train)\n",
    "print(\"gbc_train=\",gbc_train)\n",
    "\n",
    "gbc_test=model.score(X_test,y_test)\n",
    "print(\"gbc_test=\",gbc_test)\n",
    "\n",
    "accuracies_gboost= cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10) \n",
    "accuracies_gboost_mean=accuracies_gboost.mean()*100\n",
    "print(\"Accuracy Gradient Boost=\",accuracies_gboost_mean)\n",
    "\n",
    "accuracies_gboost_std=accuracies_gboost.std()*100\n",
    "print(\"Standard Deviation Gradient Boost=\",accuracies_gboost_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Bagging Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mgc_train= 0.9974097331240188\n",
      "mgc_test= 0.984\n",
      "Accuracy Bagging= 93.0223125856784\n",
      "Standard Deviation Bagging= 0.0\n"
     ]
    }
   ],
   "source": [
    "# Bagging meta estimator\n",
    "#Random subsets are created from the original dataset (Bootstrapping).\n",
    "#The subset of the dataset includes all features.\n",
    "#A user-specified base estimator is fitted on each of these smaller sets.\n",
    "#Predictions from each model are combined to get the final result.\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"mgc_train=\",model.score(X_train, y_train))\n",
    "print(\"mgc_test=\",model.score(X_test,y_test))\n",
    "\n",
    "accuracies_Bagging_MEst= cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10) \n",
    "accuracies_Bagging_MEst_Mean=accuracies_Bagging_MEst.mean()*100\n",
    "\n",
    "print(\"Accuracy Bagging=\",accuracies_Bagging_MEst_Mean)\n",
    "\n",
    "accuracies_bagging_MEst_std=accuracies_Bagging_MEst_Mean.std()*100\n",
    "print(\"Standard Deviation Bagging=\",accuracies_bagging_MEst_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evc_train= 0.984850863422292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evc_test 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy EVC= 92.11932905133776\n",
      "Standard Deviation EVC= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smukhopadhyay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "## Bagging on multiple classifiers:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "lr = LogisticRegression()\n",
    "svm=SVC(kernel = 'rbf', C=10,gamma=1)\n",
    "knn=KNeighborsClassifier(n_neighbors = 4, metric = 'minkowski', p = 2)\n",
    "nb=GaussianNB()\n",
    "dt=DecisionTreeClassifier(criterion = 'entropy')\n",
    "rf=RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "#ann_classifier=KerasClassifier(build_fn=buildClassifier_DP,batch_size = 25, epochs = 100)\n",
    "\n",
    "\n",
    "evc = VotingClassifier( estimators= [('lr',lr),('dt',dt),('svm',svm),('knn',knn),('nb',nb),('rf',rf)], voting = 'hard')\n",
    "evc.fit(X_train,y_train)\n",
    "\n",
    "print(\"evc_train=\",evc.score(X_train,y_train))\n",
    "print(\"evc_test\",evc.score(X_test,y_test))\n",
    "\n",
    "#Training_Testing_Difference_EVC=(evc.score(X_train, y_train) - evc.score(X_test, y_test))*100\n",
    "#print(Training_Testing_Difference_EVC)\n",
    "\n",
    "accuracies_EVC= cross_val_score(estimator = evc, X = X_train, y = y_train, cv = 10) \n",
    "accuracies_EVC_mean=accuracies_EVC.mean()*100\n",
    "print(\"Accuracy EVC=\",accuracies_EVC_mean)\n",
    "\n",
    "accuracies_EVC_std=accuracies_EVC_mean.std()*100\n",
    "print(\"Standard Deviation EVC=\",accuracies_EVC_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict(X_test)\n",
    "pred2=model2.predict(X_test)\n",
    "pred3=model3.predict(X_test)\n",
    "\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    final_pred = np.append(final_pred, statistics.mode([pred1[i], pred2[i], pred3[i]]))\n",
    "    \n",
    "#print(\"maxvoting_test\",evc.score(X_test,final_pred))\n",
    "#print(\"\\n\")\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, final_pred)\n",
    "print(classification_report(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=25) ## Hyperparameter\n",
    "classifier.fit(X_train,y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "accuracies_logistic= cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10) \n",
    "accuracies_logistic_mean=accuracies_logistic.mean()*100\n",
    "print(\"Mean Accuracy:Random Forest=\",accuracies_logistic_mean)\n",
    "\n",
    "accuracies_logistic_std=accuracies_logistic.std()*100\n",
    "print(\"Standard Deviation:Random Forest=\",accuracies_logistic_std)\n",
    "\n",
    "\n",
    "## Hyper Parameter Tuning\n",
    "print('Parameters currently in use:\\n')\n",
    "print(classifier.get_params())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 5)] ## play with start and stop\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 20, num = 5)] ## change 10,20 and 2\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,15]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,10]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)\n",
    "print(\"Best Parameters are:\",rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_random.fit(X_train,y_train)\n",
    "\n",
    "predictions = best_random.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "accuracies_rf= cross_val_score(estimator = best_random, X = X_train, y = y_train, cv = 10) \n",
    "accuracies_rf_mean=accuracies_rf.mean()*100\n",
    "print(\"Mean Accuracy:Random Forest=\",accuracies_logistic_mean)\n",
    "\n",
    "accuracies_rf_std=accuracies_logistic.std()*100\n",
    "print(\"Standard Deviation:Random Forest=\",accuracies_rf_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conda install -c conda-forge lightgbm\n",
    "\n",
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt' ## gradient boosting\n",
    "params['objective'] = 'binary' ## since its a classification problem\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n",
    "clf = lgb.train(params, d_train, 100)\n",
    "\n",
    "\n",
    "#Prediction\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#convert into binary values\n",
    "for i in range(0,2000): ## 10000 indicates the number of rows in the dataset\n",
    "    if y_pred[i]>=0.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "mean_score = cross_val_score(estimator = classifier, X = X_train, y = y_train, scoring=\"roc_auc\", cv = 7).mean()\n",
    "std_score = cross_val_score(estimator = classifier, X = X_train, y = y_train, scoring=\"roc_auc\", cv = 7).std()\n",
    "\n",
    "\n",
    "print (\"Accuracy=\",mean_score*100)\n",
    "print(\"Standard Deviation\",std_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "#from catboost import CatBoostRegressor -- use \"pip install catboost\" \n",
    "\n",
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "X = df.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y = df.Exited\n",
    "\n",
    "X = df.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y = df.Exited\n",
    "\n",
    "X_upsampled = df_upsampled.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y_upsampled = df_upsampled.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test_upsampled, y_train, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "categorical_features_indices = np.where(X.dtypes == np.object)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "### In Case of Regression\n",
    "##from catboost import CatBoostRegressor\n",
    "##model=CatBoostRegressor(iterations=50, depth=3, learning_rate=0.1, loss_function='RMSE')\n",
    "##model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_validation, y_validation),plot=True)\n",
    "\n",
    "model=CatBoostClassifier(iterations=100, depth=3, learning_rate=0.1, loss_function='Logloss')\n",
    "model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, y_test),plot=True)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Create a stacking with xgboost and random Forest.\n",
    "## Homework: add Gradient Boost, AdaBoost, Light GBM and CatBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "pred_val_xgb=xgb.predict(X_train)\n",
    "test_pred_xgb=xgb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_random.fit(X_train,y_train) ## Best Hyperparameters of random Forest found above\n",
    "pred_val_rf=best_random.predict(X_train)\n",
    "test_pred_rf=best_random.predict(X_test)\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "stacked_predictions=np.column_stack((pred_val_rf,pred_val_xgb))\n",
    "\n",
    "#stacked_predictions[0:10]\n",
    "stacked_test_predictions=np.column_stack((test_pred_rf,test_pred_xgb))\n",
    "#stacked_test_predictions[0:10]\n",
    "\n",
    "## Building Meta Model\n",
    "lr.fit(stacked_predictions,y_train)\n",
    "\n",
    "y_pred=lr.predict(stacked_test_predictions)\n",
    "y_pred\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred)) \n",
    "\n",
    "accuracies_lr= cross_val_score(estimator = lr, X = stacked_predictions, y = y_train, cv = 10) \n",
    "accuracies_lr_mean=accuracies_lr.mean()*100\n",
    "print(\"Accuracy Stacking=\",accuracies_lr_mean)\n",
    "\n",
    "accuracies_lr_std=accuracies_lr_mean.std()*100\n",
    "print(\"Standard Deviation lr=\",accuracies_lr_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "X = df.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y = df.Exited\n",
    "\n",
    "X = df.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y = df.Exited\n",
    "\n",
    "X_upsampled = df_upsampled.drop(['Exited','RowNumber','CustomerId','Surname'], axis=1)\n",
    "y_upsampled = df_upsampled.Exited\n",
    "\n",
    "\n",
    "### Convert Non Numerical Categorical column into numeric ones\n",
    "##Check the categories which are non numerical\n",
    "\n",
    "categoryList = list(X.select_dtypes(include=['object']).columns)\n",
    "print(categoryList)\n",
    "print(\"\\n\")\n",
    "\n",
    "## Create dummy variables for non numerical categorical variables\n",
    "dummies = pd.get_dummies(X[categoryList], prefix= categoryList)\n",
    "print(dummies.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "X.drop(categoryList, axis=1, inplace = True) ## Drop Non numerical categorical columns\n",
    "print(X.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "X=pd.concat([X,dummies], axis =1 ) ## added encoded categorical columns\n",
    "\n",
    "\n",
    "#### Do the same steps for upsampled #####\n",
    "categoryList = list(X_upsampled.select_dtypes(include=['object']).columns)\n",
    "print(categoryList)\n",
    "print(\"\\n\")\n",
    "\n",
    "## Create dummy variables for non numerical categorical variables\n",
    "dummies = pd.get_dummies(X_upsampled[categoryList], prefix= categoryList)\n",
    "print(dummies.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "X_upsampled.drop(categoryList, axis=1, inplace = True) ## Drop Non numerical categorical columns\n",
    "print(X_upsampled.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "X_upsampled=pd.concat([X_upsampled,dummies], axis =1 ) ## added encoded categorical columns\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test_upsampled, y_train, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mix independent variables and stacked outputs \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "model1 = rf_random.best_estimator_ ## Best hyperparameters of Random Forest\n",
    "model1.fit(X_train, y_train)\n",
    "val_pred1=model1.predict(X_train)\n",
    "test_pred1=model1.predict(X_test)\n",
    "\n",
    "\n",
    "model2 = XGBClassifier()\n",
    "model2.fit(X_train,y_train)\n",
    "val_pred2=model2.predict(X_train)\n",
    "test_pred2=model2.predict(X_test)\n",
    "\n",
    "\n",
    "stacked_predictions=np.column_stack((X_train,val_pred1,val_pred2))\n",
    "stacked_test_predictions=np.column_stack((X_test,test_pred1,test_pred2))\n",
    "\n",
    "stacked_predictions=pd.DataFrame(stacked_predictions)\n",
    "stacked_test_predictions=pd.DataFrame(stacked_test_predictions)\n",
    "\n",
    "## Building Meta Model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(stacked_predictions,y_train)\n",
    "\n",
    "y_pred=lr.predict(stacked_test_predictions)\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
